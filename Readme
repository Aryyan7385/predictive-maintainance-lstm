# Predictive Maintenance for Jet Engines using LSTMs

This project uses Machine Learning to predict the remaining useful life (RUL) of a jet engine. It trains a Long Short-Term Memory (LSTM) neural network on the NASA Turbofan Engine Degradation Dataset to classify an engine's state as "Healthy" or "Failure Imminent."

The final model is deployed as an interactive web application using Streamlit.



## Project Overview

Problem: Unexpected equipment failure in industrial settings, like aviation, can be catastrophic and extremely costly. We need a way to anticipate these failures before they happen.

Solution: This project builds a time-series classification model. By analyzing the history of sensor readings from an engine, the model learns to identify patterns that signal an impending failure.

- Model's Goal: To answer the question: "Based on the last 50 cycles of sensor data, will this engine fail within the next 30 cycles?"
- Class 0: Healthy (Failure not predicted within 30 cycles)
- Class 1: Failure Imminent (Failure predicted within 30 cycles)

## The Technology We Used

- Python: The core programming language.
- Pandas & Numpy: For data loading, manipulation, and numerical operations.
- Scikit-learn (sklearn): Used for data preprocessing (specifically `MinMaxScaler`).
- TensorFlow (Keras): The deep learning framework used to build and train the LSTM model.
- Joblib: For saving and loading the `MinMaxScaler` object.
- Streamlit: To create and serve the interactive web app demo.
- Jupyter Notebook: For data exploration and model development.

## How to Run This Project

### 1. Setup the Environment

First, clone or download this repository.

```bash
# Navigate to the project folder
cd ml-predictive-maintenance

# Create a virtual environment
# (You may need to use 'python' instead of 'py')
py -m venv venv

# Activate the environment
# Windows PowerShell:
.\venv\Scripts\activate
# (You may need to run this first: Set-ExecutionPolicy RemoteSigned -Scope CurrentUser)

2. Install Dependencies
With your venv active, install the required libraries:

Bash

# 'py -m pip' ensures you use the venv's pip
py -m pip install pandas numpy scikit-learn tensorflow matplotlib streamlit jupyter
3. Get the Data
You must download the NASA Turbofan Engine Degradation Dataset (FD001).

Find it on the Kaggle website (or NASA's data repository).

From the download, place these three files in the root of your project folder:

train_FD001.txt

test_FD001.txt

RUL_FD001.txt

4. Train the Model
The model is trained inside a Jupyter Notebook.

Bash

# Start the Jupyter Notebook server
jupyter notebook
Your browser will open. Click on your notebook file (e.g., Untitled.ipynb or train_model.ipynb).

Run all the cells from top to bottom.

This will process the data and, most importantly, create two files:

engine_failure_model.h5: The trained LSTM model.

sensor_scaler.pkl: The saved data scaler.

5. Run the Web App
Once the model and scaler are saved, you can run the Streamlit app.

Bash

# In your terminal (with venv active):
streamlit run app.py
Your web browser will automatically open to a local URL, and the application will be live. You can now upload a CSV of sensor data to get a live prediction.

Project Structure
ml-predictive-maintenance/
├── .venv/                      # Virtual environment folder
├── app.py                      # The Streamlit web app script
├── engine_failure_model.h5     # Your trained model (Generated by notebook)
├── sensor_scaler.pkl           # Your saved scaler (Generated by notebook)
├── train_FD001.txt             # Original training data
├── test_FD001.txt              # Original test data
├── RUL_FD001.txt               # Original RUL ground truth
├── test_engine_12.csv          # Sample test file (Generated by notebook)
├── Untitled.ipynb              # Your Jupyter Notebook for training
└── README.md                   # This file
How It All Works (The Workflow)
Load Data: The train_FD001.txt data is loaded into a Pandas DataFrame.

Label Engineering: We calculate the RUL (Remaining Useful Life) for every cycle and create a binary label (1 if RUL <= 30, 0 otherwise).

Scale Data: All sensor columns are scaled to a 0-1 range using MinMaxScaler.

Sequencing: The data is transformed from a 2D table into 3D "sequences" (or "windows") of 50 time-steps.

Train Model: An LSTM model is built and trained on these 3D sequences.

Save Artifacts: The final model (.h5) and scaler (.pkl) are saved to disk.

Serve App: app.py loads these two artifacts, takes a user-uploaded CSV, performs the exact same scaling and sequencing, and feeds the data to the model to get a live prediction.
