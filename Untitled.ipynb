{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058e8224-36dc-4466-93c3-182bf75b65eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "     unit_number   cycle  setting1  setting2  setting3  sensor1  sensor2  \\\n",
      "1 1      -0.0007 -0.0004     100.0    518.67    641.82  1589.70  1400.60   \n",
      "  2       0.0019 -0.0003     100.0    518.67    642.15  1591.82  1403.14   \n",
      "  3      -0.0043  0.0003     100.0    518.67    642.35  1587.99  1404.20   \n",
      "  4       0.0007  0.0000     100.0    518.67    642.35  1582.79  1401.87   \n",
      "  5      -0.0019 -0.0002     100.0    518.67    642.37  1582.85  1406.22   \n",
      "\n",
      "     sensor3  sensor4  sensor5  ...  sensor10  sensor11  sensor12  sensor13  \\\n",
      "1 1    14.62    21.61   554.36  ...    521.66   2388.02   8138.62    8.4195   \n",
      "  2    14.62    21.61   553.75  ...    522.28   2388.07   8131.49    8.4318   \n",
      "  3    14.62    21.61   554.26  ...    522.42   2388.03   8133.23    8.4178   \n",
      "  4    14.62    21.61   554.45  ...    522.86   2388.08   8133.83    8.3682   \n",
      "  5    14.62    21.61   554.00  ...    522.19   2388.04   8133.80    8.4294   \n",
      "\n",
      "     sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \n",
      "1 1      0.03       392      2388     100.0     39.06   23.4190  \n",
      "  2      0.03       392      2388     100.0     39.00   23.4236  \n",
      "  3      0.03       390      2388     100.0     38.95   23.3442  \n",
      "  4      0.03       392      2388     100.0     38.88   23.3739  \n",
      "  5      0.03       393      2388     100.0     38.90   23.4044  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the column names as per the dataset's documentation\n",
    "col_names = ['unit_number', 'cycle', 'setting1', 'setting2', 'setting3']\n",
    "col_names += ['sensor' + str(i) for i in range(1, 22)]\n",
    "\n",
    "# Load the training data\n",
    "df_train = pd.read_csv('train_FD001.txt', sep=' ', header=None, names=col_names)\n",
    "\n",
    "# Drop the last two columns (they are empty/NaN)\n",
    "df_train.dropna(axis=1, inplace=True)\n",
    "\n",
    "print(\"Data loaded successfully:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21bcb18-bcb4-4607-9601-4e1d2cd16a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [col for col in df_train.columns if col.startswith('sensor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacc61ed-7587-4c62-89a3-cc0a73b45ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the last cycle (failure point) for each engine\n",
    "max_cycles = df_train.groupby('unit_number')['cycle'].max().to_frame(name='max_cycle')\n",
    "\n",
    "# Merge this back into the main dataframe\n",
    "df_train = df_train.merge(max_cycles, left_on='unit_number', right_index=True)\n",
    "\n",
    "# Calculate the RUL for each row\n",
    "df_train['RUL'] = df_train['max_cycle'] - df_train['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16269fd-26ae-4fe7-83c0-0f50860b7174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with labels:\n",
      "         unit_number   cycle  setting1  setting2  setting3  sensor1  sensor2  \\\n",
      "100 196      -0.0004 -0.0003     100.0    518.67    643.49  1597.98  1428.63   \n",
      "    197      -0.0016 -0.0005     100.0    518.67    643.54  1604.50  1433.58   \n",
      "    198       0.0004  0.0000     100.0    518.67    643.42  1602.46  1428.18   \n",
      "    199      -0.0011  0.0003     100.0    518.67    643.23  1605.26  1426.53   \n",
      "    200      -0.0032 -0.0005     100.0    518.67    643.85  1600.38  1432.14   \n",
      "\n",
      "         sensor3  sensor4  sensor5  ...  sensor11  sensor12  sensor13  \\\n",
      "100 196    14.62    21.61   551.43  ...   2388.26   8137.60    8.4956   \n",
      "    197    14.62    21.61   550.86  ...   2388.22   8136.50    8.5139   \n",
      "    198    14.62    21.61   550.94  ...   2388.24   8141.05    8.5646   \n",
      "    199    14.62    21.61   550.68  ...   2388.23   8139.29    8.5389   \n",
      "    200    14.62    21.61   550.79  ...   2388.26   8137.33    8.5036   \n",
      "\n",
      "         sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  label  \n",
      "100 196      0.03       397      2388     100.0     38.49   22.9735      1  \n",
      "    197      0.03       395      2388     100.0     38.30   23.1594      1  \n",
      "    198      0.03       398      2388     100.0     38.44   22.9333      1  \n",
      "    199      0.03       395      2388     100.0     38.29   23.0640      1  \n",
      "    200      0.03       396      2388     100.0     38.37   23.0522      1  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define our \"failure window\"\n",
    "FAILURE_WINDOW = 30\n",
    "\n",
    "# Create the label: 1 if RUL <= 30, 0 otherwise\n",
    "df_train['label'] = (df_train['RUL'] <= FAILURE_WINDOW).astype(int)\n",
    "\n",
    "# We don't need these columns anymore\n",
    "df_train.drop(columns=['max_cycle', 'RUL'], inplace=True)\n",
    "\n",
    "print(\"Data with labels:\")\n",
    "print(df_train.tail()) # .tail() shows the end of an engine's life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d88f365-58fe-4b1a-9682-82d47e63cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data scaled and scaler saved to 'sensor_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the sensor columns\n",
    "df_train[sensor_cols] = scaler.fit_transform(df_train[sensor_cols])\n",
    "\n",
    "# Save this scaler object to a file. We NEED this for the test data and our app.\n",
    "joblib.dump(scaler, 'sensor_scaler.pkl')\n",
    "print(\"Sensor data scaled and scaler saved to 'sensor_scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75cc4c37-de94-42ec-902e-354158fd9d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15426, 50, 19)\n",
      "y_train shape: (15426,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "# Iterate over each unique engine\n",
    "for unit in df_train['unit_number'].unique():\n",
    "    # Get all data for this one engine\n",
    "    engine_data = df_train[df_train['unit_number'] == unit]\n",
    "\n",
    "    # Get this engine's sensor data and labels as numpy arrays\n",
    "    sensor_data = engine_data[sensor_cols].values\n",
    "    labels = engine_data['label'].values\n",
    "\n",
    "    # Create sliding windows\n",
    "    for i in range(len(sensor_data) - SEQUENCE_LENGTH + 1):\n",
    "        # The sequence of features (X)\n",
    "        X_train_list.append(sensor_data[i : i + SEQUENCE_LENGTH])\n",
    "\n",
    "        # The label (y) for that sequence (taken from the LAST step)\n",
    "        y_train_list.append(labels[i + SEQUENCE_LENGTH - 1])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "\n",
    "# Check the final 3D shape\n",
    "print(f\"X_train shape: {X_train.shape}\") # (num_samples, 50, num_sensors)\n",
    "print(f\"y_train shape: {y_train.shape}\") # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edbce4af-8d3e-4156-9b23-d2fa19264fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0eaab6-83a3-4302-b7e3-1fba2661c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\OneDrive\\Documents\\ml-predictive-maintenance\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m14,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,251</span> (133.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,251\u001b[0m (133.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,251</span> (133.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,251\u001b[0m (133.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the number of features (e.g., 14 sensors)\n",
    "num_features = X_train.shape[2] \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer (LSTM)\n",
    "# 50 units, return_sequences=True because we stack another LSTM\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(SEQUENCE_LENGTH, num_features)))\n",
    "model.add(Dropout(0.2)) # Prevents overfitting\n",
    "\n",
    "# Hidden Layer (LSTM)\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer (Dense)\n",
    "# 1 unit (probability of failure)\n",
    "# 'sigmoid' activation for binary classification (output between 0 and 1)\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ef626d-9127-401f-aa37-c65812705f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - accuracy: 0.9957 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 1.5782e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.4675e-04 - val_accuracy: 1.0000 - val_loss: 7.3870e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.3337e-05 - val_accuracy: 1.0000 - val_loss: 4.7983e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.9213e-05 - val_accuracy: 1.0000 - val_loss: 3.5204e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 4.5873e-05 - val_accuracy: 1.0000 - val_loss: 2.6934e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.5786e-05 - val_accuracy: 1.0000 - val_loss: 2.1253e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.8636e-05 - val_accuracy: 1.0000 - val_loss: 1.7351e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.4130e-05 - val_accuracy: 1.0000 - val_loss: 1.4564e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.0906e-05 - val_accuracy: 1.0000 - val_loss: 1.2421e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.7986e-05 - val_accuracy: 1.0000 - val_loss: 1.0727e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Model saved to 'engine_failure_model.h5'\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10,        # 10 epochs is a good start\n",
    "    batch_size=64,\n",
    "    validation_split=0.2 # Use 20% of data for validation\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Save the trained model to a file\n",
    "model.save('engine_failure_model.h5')\n",
    "print(\"Model saved to 'engine_failure_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16bd2e-0b40-4b37-baf4-b56bc7e41a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
